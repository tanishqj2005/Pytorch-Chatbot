{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk_utils import tokenize, stem, bag_of_words\n",
    "import numpy as np\n",
    "\n",
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))\n",
    "\n",
    "ignore_words = ['?', '!', '.', ',']\n",
    "\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(list(set(all_words)))\n",
    "tags = sorted(list(set(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for (pattern,tag) in xy:\n",
    "    bag = bag_of_words(pattern,all_words)\n",
    "    X_train.append(bag)\n",
    "    \n",
    "    label = tags.index(tag)\n",
    "    Y_train.append(label) #Cross entropy loss\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = Y_train\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters:\n",
    "\n",
    "batch_size = 8\n",
    "hiddenSize = 8\n",
    "numOfClasses = len(tags)\n",
    "inputSize = len(X_train[0])\n",
    "learningRate = 0.001\n",
    "numEpochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, numOfClasses):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(inputSize,hiddenSize)\n",
    "        self.l2 = nn.Linear(hiddenSize, hiddenSize)\n",
    "        self.l3 = nn.Linear(hiddenSize, numOfClasses)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(inputSize,hiddenSize,numOfClasses).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/1000, loss = 0.0239\n",
      "epoch 200/1000, loss = 0.0132\n",
      "epoch 300/1000, loss = 0.0064\n",
      "epoch 400/1000, loss = 0.0024\n",
      "epoch 500/1000, loss = 0.0008\n",
      "epoch 600/1000, loss = 0.0003\n",
      "epoch 700/1000, loss = 0.0010\n",
      "epoch 800/1000, loss = 0.0008\n",
      "epoch 900/1000, loss = 0.0002\n",
      "epoch 1000/1000, loss = 0.0001\n",
      "final loss, loss = 0.0001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(numEpochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        \n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(words)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #backward and optimizer:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if ( (epoch +1) % 100 == 0):\n",
    "        print(f'epoch {epoch+1}/{numEpochs}, loss = {loss.item():.4f}')\n",
    "        \n",
    "print(f'final loss, loss = {loss.item():.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete. File saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"model_state\" : model.state_dict(),\n",
    "    \"input_size\" : inputSize,\n",
    "    \"output_size\" : numOfClasses,\n",
    "    \"hidden_size\" : hiddenSize,\n",
    "    \"all_words\" : all_words,\n",
    "    \"tags\" : tags,\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'Training Complete. File saved to {FILE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from nltk_utils import bag_of_words, tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputSize = data['input_size']\n",
    "outputSize = data['output_size']\n",
    "hiddenSize = data['hidden_size']\n",
    "\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "\n",
    "modelState = data['model_state']\n",
    "\n",
    "model = NeuralNet(inputSize,hiddenSize,numOfClasses)\n",
    "model.load_state_dict(modelState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=55, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's Chat! Type 'quit' to exit. \n",
      "You: Hi \n",
      "Oliver: Hi there, how can I help?\n",
      "You: Hi\n",
      "Oliver: Hi there, how can I help?\n",
      "You: What do you sell\n",
      "Oliver: We have coffee and tea\n",
      "You: How long\n",
      "Oliver: Hello, thanks for visiting\n",
      "You: SHipping time\n",
      "Oliver: I do not understand :( \n",
      "You: How long does shipping take\n",
      "Oliver: Shipping takes 2-4 days\n",
      "You: joke\n",
      "Oliver: I do not understand :( \n",
      "You: tell me a joke\n",
      "Oliver: What did the buffalo say when his son left for college? Bison.\n",
      "You: bbye\n",
      "Oliver: I do not understand :( \n",
      "You: bye\n",
      "Oliver: See you later, thanks for visiting\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "bot_name = \"Oliver\"\n",
    "\n",
    "print(\"Let's Chat! Type 'quit' to exit. \")\n",
    "\n",
    "while True:\n",
    "    sentence = input('You: ')\n",
    "    if(sentence == 'quit'):\n",
    "        break\n",
    "    \n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence,all_words)\n",
    "    \n",
    "    X = X.reshape(-1,X.shape[0])\n",
    "    \n",
    "    X = torch.from_numpy(X)\n",
    "    \n",
    "    output = model(X)\n",
    "    \n",
    "    _, predicted = torch.max(output,dim = 1)\n",
    "    \n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim = 1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    \n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent['tag']:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f'{bot_name}: I do not understand :( ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
